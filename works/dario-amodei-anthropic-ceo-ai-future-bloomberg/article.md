# Anthropic CEO Dario Amodei on the Future of AI

*Bloomberg Live Interview at Davos*

---

## The State of AI Progress

**Interviewer:** Can we start with the kind of rough status of how the industry is going? You and your rivals, how close are we now to **artificial general intelligence**? Set the stage for us first and then we can talk about the morality of it all.

**Dario Amodei:** Thanks for having me. I mean, you know, I've never liked the artificial general intelligence or superintelligence—not because I don't think it's very powerful. I'm not a skeptic. I'm actually extreme in terms of my views of how powerful the technology is going to be.

But it's the wrong model for thinking about it, that there will be some one point where we build something completely different. What we see here, actually, what we've seen for the last ten years, maybe even 15—and me and the Anthropic co-founders were among the first to document it—is this very smooth, **exponential process**.

Just like in the nineties, you saw **Moore's Law** that the amount of computing power would double every 12 months or every 18 months. We have a Moore's Law-like law, except it's for **intelligence itself**, for the cognitive ability of the model across many tasks. And so what we are seeing is that cognitive ability is, depending on how you measure it, **doubling every 4 to 12 months**.

We're just climbing the ladder of cognitive ability.

---

## AI in Software Development

And where we are now is—to take **coding** as one example that's been exploding really fast over the last year or two—I have engineers. In fact, the team that leads one of our lead products called **Claude Code**, which is the way you use our models for coding... he says he hasn't written any code in the last two months. He's edited it, he's looked at it, but it's all been written by Claude.

Indeed, we recently released this thing called **Claude Code**, which was bringing Claude Code to non-coding tasks. It really seems to have taken off. We wrote it in like a week and a half, almost entirely with Claude Code.

So I think we're entering the world where the **junior level software engineers**, maybe many of the tasks of the more senior level software engineers, are starting to be done most of the way by AI systems. Now that's going to go further, it can be more end-to-end, the projects can be more complex.

But I think we're going to be surprised at how the exponential turns upward. The whole thing about exponentials is it looks like it's going very, very slowly, it speeds up a little bit, and then it just **zooms past you**.

*"I think we're on the precipice. I think we're a year or two away from it really zooming past us."*

---

## The Competitive Landscape

**Interviewer:** When this happens, in terms of the running order—yourself, Gemini, OpenAI—where do you put you all together at the moment roughly?

**Dario Amodei:** I think as the field has developed, it's no longer appropriate to think of it as like runners in a race who are at one position. The players have gone in **different directions**.

So some of the other players have gone into a very **consumer-oriented direction**. And that leads you to make your models super humanly engaging or super humanly good at recommending shopping or ads or various things like that.

**Anthropic** has focused, I think, first and foremost on **enterprises** and **developers**. And to the extent we do consumer, we're very focused on productivity and the high-value end of the consumer work. That gives very different incentives.

You know, we talked about AGI and superintelligence before. One of the things I would say is that there are superintelligences today and they're basically **large corporations**. They're smarter than any human can be at solving problems like shipping commerce at the lowest possible cost, or making solar panels at the lowest possible cost, or launching rockets at the lowest possible cost.

There's really high returns to intelligence in this area, which I think incentivizes us to build the right thing. It's also a business that is **more stable than consumer**. We don't need ads. We don't need large numbers of free users. We can just very directly create value. There aren't all these weird externalities of prioritizing engagement, generating all this slop. We just make stuff that people can use.

---

## China and the Chip Debate

**Interviewer:** A year ago here, you said the Chinese were catching up a bit. Do you think now the Chinese have fallen behind?

**Dario Amodei:** I think they never really caught up that much. Of course, there was this huge excitement around **DeepSeek**. But the truth was a couple of things.

One, those models are very optimized for the benchmarks. It's actually very easy to optimize the model for a finite list of benchmarks. When we go out into the world, when we're competing against other companies for enterprise contracts, we see Google and we see OpenAI. Every once in a while, we see a couple other U.S. players. **I have almost never lost a deal, lost a contract to a Chinese model.**

**Interviewer:** But now you have the Trump administration, and I think you've already protested about this, giving high-speed chips and NVIDIA chips to the Chinese.

**Dario Amodei:** That's right. The thing that is holding them back—and they've said it themselves, the CEOs of these companies say it's the **embargo on chips** that's holding us back. They explicitly say this.

And now there are some policies—and I hope they change their mind—to explicitly send not quite our latest generation of chips, although it was reported that even that was being considered. But the generation of chips that's just one back is still extremely powerful. And we are **many years ahead of China** in terms of our ability to make chips.

So I think it would be a **big mistake** to ship these chips. If you think about the incredible national security implications of building models that are essentially cognition, that are essentially intelligence... I've called where we're going with this *"a country of geniuses in the data center."* Imagine 100 million people smarter than any Nobel Prize winner. And it's going to be under the control of one country or another.

*"I think this is crazy. It's a bit like selling nuclear weapons to North Korea."*

---

## The Economic Bubble Question

**Interviewer:** Another issue—you could be right that all this technology is going in the right direction, but economically we could be heading towards a **bubble**. Do you think that's true?

**Dario Amodei:** I would separate out the two things. One is the basic exponential—that's what we've been talking about, the technological direction. Just like with Moore's Law, you can never be sure that the technology is fully going to keep advancing. It's a fundamentally inductive problem.

But now that I've seen well over a decade of it, I would say I am pretty confident that it's going to continue. I'm more confident than I've ever been at any time in the past that it's going to continue to where the **models are basically smarter than humans at almost everything**.

And I think there's a good chance that even happens in the **next year or two**. Again, it seems far away, but this property of exponentials—they catch you by surprise. And if it's not a year or two, I think it's pretty likely that it's at least less than five years, within the 2020s.

As long as we have that fundamental technological gain, there's going to be **many trillions of revenue**, maybe many trillions per company in this area, because the economic potential is so great.

Now there's a separate thing: we don't know how fast enterprises and companies are actually going to be able to **use this technology**. The uses of this, what the technology is capable of today, is probably **ten times** what enterprises are able to deploy.

I see it with our customers every day. I'll talk to a CEO and they'll understand the power of this technology for automating customer service, for coding, for many other things. But they have a company of tens of thousands of people who are perfectly brilliant people but expert in something that is not AI—and have to learn to use AI. That **change management**, enterprise transformation, is very slow. It can take years.

So we have this powerful technology that I have an incredible amount of confidence will generate trillions in revenue. But we don't know exactly when, plus or minus a few years. In the meantime, companies have to buy compute to serve all that revenue. You don't want to buy too much because you could financially overextend yourself, and you don't want to buy too little because then you can't serve all the revenue.

And I do think that **some companies have probably overbought**. I'm not able to look at their financials, I just know what they announce, and I'm like, "Whoa, I wouldn't necessarily have done that." I'm pretty happy with the decisions that we've made.

But it is entirely consistent that this could be the **most transformative technology in the history of the world**, that some companies will do really well, but not every company.

---

## The Employment Question

**Interviewer:** Obviously, as you said, it's going to have a positive effect on GDP, perhaps on your wealth too. But what about **employment**? Last year you predicted the kind of white-collar bloodbath. You said it would wipe out **50% of entry-level jobs**. That's now four and a half years away. Do you still stand by that?

**Dario Amodei:** My view of AI—there's maybe two axes. There's good things happening versus bad things happening. And there's AI is a small deal versus AI is a big deal. My view is on the extreme side of AI is a big deal, but I'm in both top quadrants where I think some **really good things** will happen. And if we don't act to prevent them, some **really bad things** will happen.

I wouldn't be building this technology if I didn't believe that the good outweighed the bad and that we could mitigate the bad. That's why I warn about the bad—so that we can address it.

I think we could have this very unusual combination of **very fast GDP growth and high unemployment**—or at least underemployment, or a lot of low-wage jobs, high inequality. I don't think that's a macroeconomic combination we've ever seen before. You think of fast growth, you're like, well, okay, maybe there's inflation, but you're not going to have high unemployment when there's fast growth.

I think this technology is different because it's extreme in the way it's going to generate value. But also because it's **moving up the cognitive waterline**, there's going to be, unfortunately, a whole class of people who are, across a lot of industries, going to have a hard time coping. And that's really a problem we need to solve.

---

## The Anthropic Economic Index

There's a few things Anthropic is doing. One is we maintain for almost a year now what we call the **Anthropic Economic Index**, which is tracking how our models are used in real time.

Because we see all these conversations, we can use Claude itself to—in a privacy-preserving manner—look across all the conversations and ask questions like: Is someone using this to **augment** a task to work together with the model, or to **delegate** or fully automate a task? What are the industries people are using Claude for, statistically by distribution? What are the subtasks within those industries?

We can get into a lot of these very fine-grained Labor Department statistics. Which states are using Claude more? We can watch the **economic diffusion** of Claude in real time.

The reason to do all this is that I don't think you can make good policy if you don't have the right data. And I worry that the data that the government produces, as comprehensive as it is, just doesn't move fast enough and isn't detailed enough for this.

---

## Higher Taxes and Wealth Inequality

**Interviewer:** You're describing a perfect storm. You have GDP going up, the wealth of certain people going massively up. And you are saying 50% of entry-level jobs go, people in real distress. You are surely going to see a political change coming from this.

**Dario Amodei:** I actually do believe that. I think this one is going to be big enough that at some point everyone's going to come to the realization that there needs to be some kind of **macroeconomic intervention**.

If we look at just the disparities in wealth that we have now, if we look at it as a fraction of GDP, I believe we've kind of **exceeded the Gilded Age** already. And this is mostly without AI. So I think things are going to go even further.

My guess is this is not even going to be a partisan thing.

**Interviewer:** There's a **wealth tax** now in California. Are you supportive of that?

**Dario Amodei:** No, I think it's a great start. I think that's poorly designed. My worry would be if we don't think about these things in a sober way, then we'll get things that are poorly designed.

That would be my message to the others in the world who are doing well in this boom: if we don't think **proactively** about how to make this revolution work for everyone, we will get these proposals that don't make sense.

---

## Existential Risk and AI Safety

**Interviewer:** Not that long ago I went to a panel with a couple of your rivals, where they put forward all the good things AI would do. And then someone said, what about the risks? And one of them rather casually said, *"Well, of course there's extinction risk"* and then moved on. And collectively around the room, people took a deep breath.

**Dario Amodei:** I've long been worried about that as well. Just as I said, this is a very powerful technology. Therefore the benefits are extreme. We're going to be able to do things like really, seriously cure cancer, or maybe eradicate tropical diseases.

But on the other side, look, we're building **cognitive systems that have their own autonomy**. And we really need to think about that. Anthropic has been founded since the beginning with an intention to think about that.

We publish probably three or four times a month research on how to **control these models**, how to make sure that they do what we want them to do and they don't run out of control.

One of my co-founders, **Chris Olah**, is arguably the inventor of a field called **mechanistic interpretability**, which is basically when you look inside the brain—the artificial brain of Claude or another AI model—and try to trace mechanistically why it's doing exactly what it's doing.

We've seen things inside the model like, in lab environments, sometimes the models will develop the **intent to blackmail**, the **intent to deceive**. And this isn't unique to Claude. If anything, this is worse in other models. These are things that if we don't train the models in the right way can emerge.

But we've pioneered the science of looking inside them so we can diagnose them and prevent the models from behaving this way, intervene and retrain the models.

We've supported various light-touch, **transparency-focused measures** for making sure that all the companies have to talk about the tests that they run. We always disclose our tests. We try to stress-test our models to get them to do the worst things possible in a test environment so that they never do those things in the real world.

---

## Setting an Example for the Industry

**Interviewer:** There is an impression that most of your peers are going heads down and they're thinking purely about whether they can just keep ahead of the other. Do you think your industry is kind of immature in that way?

**Dario Amodei:** I can't speak to what the other players are doing or why they're doing it. I think there are at least some other players in the ecosystem who I think of as responsible, who are at least thinking of things in the right way. I agree there are others who are not.

But what I have always tried to do, and what Anthropic has always tried to do, is to **set an example** and to try to inspire others to follow the example.

We always publish our work on mechanistic interpretability. We always publish the tests we run. And honestly, there are a lot of other companies where their researchers basically say, *"Hey, why can't we do that too? That seems like a responsible thing to do. That seems like the right way to develop the technology."*

So you can kind of have an effect on the other players in the ecosystem.

---

## On Politics and the Trump Administration

**Interviewer:** One very clear zone where you are different from your peers—you have not very obviously queued up to kiss the ring of Donald J. Trump. What do you think of the current US President?

**Dario Amodei:** I would really put it in a different way. I don't think being for or against administrations or for or against politicians is the right approach, or that Anthropic has anything to say one way or another on those topics.

What Anthropic knows is AI. Anthropic knows very well the **policy issues around AI**. And our approach—which indeed may have been different—is we think through the issues, we try and get a substantive view based on those issues, and then we **say what we think**.

Sometimes we will disagree with the current administration, just as we sometimes disagreed with the last administration—like with China. And sometimes we agree. It's worth highlighting the areas of agreement, like the energy data center buildouts. We did this health pledge at the White House.

But when it comes to things like the chips to China, yeah, we disagree. When it comes to putting a moratorium on state regulation, yeah, we disagree—because we disagree **on the merits**. It's not about liking or disliking a particular person. I don't think that kind of thinking is going to get us out of this situation. We have to think based on substance.

**Interviewer:** Are you going to see him when he comes to Davos tomorrow?

**Dario Amodei:** I may. I think that would be an interesting change.

---

## Anthropic's Future

**Interviewer:** What happens to Anthropic? Since you have supposedly a **$350 billion implied valuation**, would you consider an IPO this year?

**Dario Amodei:** We are most focused on just trying to make the best models and just trying to build products on top of those models and just trying to sell those models to enterprises in ways that are useful. There are large capital needs for the field, so that should be considered. But that's where our focus is.

**Interviewer:** That implies that you do need a lot of money though.

**Dario Amodei:** I mean, you don't need to ask me to know that this is capital-intensive.

**Interviewer:** So an IPO isn't completely out of the question?

**Dario Amodei:** It's never completely out of the question.

**Interviewer:** Those—the IPO and Donald Trump—both possibles in your life. Dario, thank you very much for talking to us. We now know all about mechanistic interpretability and we've had a view inside your brain—and it's not a bad one.

**Dario Amodei:** Thank you for having me, John.
