# Core Ideas: Dario Amodei Bloomberg Interview (Davos)

## AI Progress Model
- Rejects "AGI singularity" framing—AI progress is a smooth exponential, not a sudden breakthrough
- "Moore's Law for intelligence": cognitive ability doubling every 4-12 months
- Exponentials deceive—looks slow, then "zooms past you"
- Predicts human-level AI capability within 1-2 years (high confidence), definitely within 2020s

## Competitive Strategy
- Anthropic focuses on enterprise/developers, not consumers
- Competitors optimizing for "engagement" and "slop"; Anthropic optimizes for productivity
- Enterprise business more stable, better margins, no ads needed
- "Large corporations are already superintelligences"—solving shipping, solar, rockets at lowest cost

## China & National Security
- Chinese AI models overrated—"optimized for benchmarks," not real-world competitive
- "Almost never lost a deal to a Chinese model"
- Chip embargo is working—Chinese CEOs admit it's their bottleneck
- Strongly opposes chip exports to China: "like selling nuclear weapons to North Korea"
- AI = "country of geniuses in a data center"—geopolitical control stakes are existential

## Economic Outlook
- Not a tech bubble, but timing uncertainty creates financial risk for some companies
- 10x gap between AI capability and enterprise deployment capacity
- Change management is the bottleneck—takes years regardless of tech readiness
- Some companies have "overbought" compute; Anthropic more conservative
- Multi-trillion dollar revenue potential per company if exponential continues

## Employment Disruption
- Maintains "white-collar bloodbath" prediction: 50% of entry-level jobs displaced
- Unprecedented macro combination: fast GDP growth + high unemployment
- "Moving up the cognitive waterline"—whole class of people will struggle to adapt
- Created "Anthropic Economic Index" to track AI labor impact in real-time
- Government data "doesn't move fast enough" for good policy

## Wealth & Taxation
- Current wealth inequality "exceeds the Gilded Age"—mostly without AI
- AI will make it dramatically worse
- "Macroeconomic intervention" is inevitable, won't be partisan
- California wealth tax is "poorly designed" but "a great start"
- Message to tech peers: design solutions proactively or face bad reactive policy

## AI Safety
- Building "cognitive systems with autonomy"—must think seriously about control
- Mechanistic interpretability (Chris Olah): looking inside AI "brains" to understand behavior
- Lab observations: models can develop "intent to blackmail, intent to deceive"
- Anthropic publishes safety research 3-4x per month
- Stress-tests models to fail in labs so they don't fail in the real world

## Coding as Leading Indicator
- Anthropic engineer hasn't written code in 2 months—all by Claude, he just edits
- Claude Code built in 1.5 weeks, almost entirely by Claude
- Junior engineer tasks mostly automatable now; senior tasks increasingly so
- Trajectory: more end-to-end, more complex projects handled by AI

## Politics & Leadership
- Substance over politics: evaluate policies on merits, not party
- Disagrees with Trump on chips-to-China, state regulation moratorium
- Agrees with Trump on energy/data center buildouts
- Leads by example—publishes research, discloses tests, influences competitors' researchers
- Willing to meet Trump at Davos: "I may. That would be an interesting change."

## Amodei's Worldview
- Two axes: (big deal vs small deal) × (good vs bad outcomes)
- Amodei: extreme "big deal" + believes both good AND bad outcomes will happen
- Justification for building: "good outweighs bad, and we can mitigate the bad"
- "Reluctant accelerationist"—transformation inevitable, responsible actors must lead
- Mental model: **managed inevitability**—the exponential is coming, question is who controls it
